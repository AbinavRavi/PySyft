{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "# Federated Learning Training Plan: Execute Plan\n",
    "\n",
    "Here we load and execute Plan and Model params created earlier in \"Create Plan\" notebook. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.13.1.so'\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import syft as sy\n",
    "import torch as th\n",
    "from torchvision import datasets, transforms\n",
    "from syft.serde import protobuf\n",
    "import base64\n",
    "from syft_proto.messaging.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.messaging.v1.state_pb2 import State as StatePB\n",
    "from syft_proto.types.torch.v1.script_function_pb2 import ScriptFunction as ScriptFunctionPB\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sy.hook(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility func that unserializes file contents into PySyft classes.\n",
    "Note that we must know file contents beforehand to use specific protobuf class for deserialization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def deserializeFromBase64(worker, filename, pb):\n",
    "    \n",
    "    with open(filename, \"r\") as f:\n",
    "        str = f.read()\n",
    "    bin = base64.b64decode(str)\n",
    "    pb.ParseFromString(bin)\n",
    "    return protobuf.serde._unbufferize(worker, pb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Unserialize "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loaded plan (# of ops): 43\n",
      "Loaded tracescript plan code: def forward(self,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: Tensor,\n",
      "    argument_5: Tensor,\n",
      "    argument_6: Tensor,\n",
      "    argument_7: Tensor,\n",
      "    argument_8: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0 = torch.matmul(argument_1, torch.t(argument_5))\n",
      "  _1 = torch.add(_0, argument_6, alpha=1)\n",
      "  _2 = torch.relu(_1)\n",
      "  _3 = torch.add(torch.matmul(_2, torch.t(argument_7)), argument_8, alpha=1)\n",
      "  _4 = torch.softmax(_3, 1, None)\n",
      "  _5 = torch.mean(torch.mul(argument_2, torch.log(_4)), dtype=None)\n",
      "  _6 = torch.neg(_5)\n",
      "  _7 = ops.prim.NumToTensor(torch.size(argument_2, 1))\n",
      "  _8 = torch.div(torch.sub(_4, argument_2, alpha=1), torch.mul(argument_3, _7))\n",
      "  _9 = torch.matmul(_8, argument_7)\n",
      "  _10 = torch.to(torch.gt(_1, 0), 6, False, False, None)\n",
      "  _11 = torch.mul(_9, _10)\n",
      "  _12 = torch.matmul(torch.t(_11), argument_1)\n",
      "  _13 = torch.sum(_11, [0], False, dtype=None)\n",
      "  _14 = torch.matmul(torch.t(_8), _2)\n",
      "  _15 = torch.sum(_8, [0], False, dtype=None)\n",
      "  _16 = torch.mul(torch.neg(_12), argument_4)\n",
      "  _17 = torch.mul(torch.neg(_13), argument_4)\n",
      "  _18 = torch.mul(torch.neg(_14), argument_4)\n",
      "  _19 = torch.mul(torch.neg(_15), argument_4)\n",
      "  _20 = torch.eq(torch.argmax(_4, 1, False), torch.argmax(argument_2, 1, False))\n",
      "  _21 = torch.to(_20, 6, False, False, None)\n",
      "  _22 = torch.add_(argument_5, _16, alpha=1)\n",
      "  _23 = torch.add_(argument_6, _17, alpha=1)\n",
      "  _24 = torch.add_(argument_7, _18, alpha=1)\n",
      "  _25 = torch.add_(argument_8, _19, alpha=1)\n",
      "  _26 = torch.div(torch.sum(_21, dtype=None), argument_3)\n",
      "  return (_22, _23, _24, _25, _6, _26)\n",
      "\n",
      "Loaded params count: 4\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "training_plan_ops = deserializeFromBase64(hook.local_worker, \"tp_ops.b64\", PlanPB())\n",
    "training_plan_ts = deserializeFromBase64(hook.local_worker, \"tp_ts.b64\", ScriptFunctionPB())\n",
    "model_params_state = deserializeFromBase64(hook.local_worker, \"model_params.b64\", StatePB())\n",
    "# unwrap tensors from State\n",
    "model_params = model_params_state.tensors()\n",
    "\n",
    "print(\"Loaded plan (# of ops):\", len(training_plan_ops.operations))\n",
    "print(\"Loaded tracescript plan code:\", training_plan_ts.code)\n",
    "print(\"Loaded params count:\", len(model_params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Train!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "mnist = th.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "def execute_training_plan(data, plan, model_params, epochs=3, batch_size=th.tensor(batch_size), lr=th.tensor(0.01)):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for batch_idx, (X, y) in enumerate(data):\n",
    "            X = X.view(X.shape[0], -1)\n",
    "            y_oh = th.nn.functional.one_hot(y, 10)\n",
    "            *model_params, loss, acc = plan(X, y_oh, batch_size, lr, *model_params)\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(acc.item())\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"Batch %d, loss: %f, accuracy: %f\" % (batch_idx, loss, acc), end=\"\\r\")\n",
    "        print('Epoch %d, avg loss: %f, avg training accuracy: %f' % (epoch, np.mean(losses), np.mean(accuracies)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1, avg loss: 0.207533, avg training accuracy: 0.444013\n",
      "Epoch 2, avg loss: 0.157925, avg training accuracy: 0.732126\n",
      "Epoch 3, avg loss: 0.119505, avg training accuracy: 0.789346\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Plain Plan\n",
    "execute_training_plan(mnist, training_plan_ops, model_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1, avg loss: 0.094847, avg training accuracy: 0.818563\n",
      "Epoch 2, avg loss: 0.079739, avg training accuracy: 0.835871\n",
      "Epoch 3, avg loss: 0.069991, avg training accuracy: 0.846848\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Torchscript Plan\n",
    "execute_training_plan(mnist, training_plan_ts, model_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}